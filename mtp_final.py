# -*- coding: utf-8 -*-
"""MTP_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N5LKSKJ0GAEK8wDXj2WIHrKCgeNN9LXg
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.image import imread
import cv2
import random
import os
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import img_to_array, array_to_img
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from keras.callbacks import EarlyStopping

plt.figure(figsize=(12,12))
path = "/content/drive/MyDrive/MTP_Rice_Dataset/Stressed"

def load_jpg_image(file_path):
    image = cv2.imread(file_path)
    if image is not None:
        image = cv2.resize(image, (256, 256))
        return image
    else:
        print(f"Unable to read image: {file_path}")
        return np.array([])

plt.figure(figsize=(10, 10))

for i in range(1, 17):
    plt.subplot(4, 4, i)
    plt.tight_layout()

    # Choose a random file from the list
    random_file = random.choice(sorted(os.listdir(path)))
    file_path = os.path.join(path, random_file)

    # Load the image using the appropriate function based on its format
    rand_img = load_jpg_image(file_path)

    plt.imshow(rand_img)

def extract_features(image):
    # Example: Extract HOG features
    hog = cv2.HOGDescriptor()
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    hog_features = hog.compute(gray)

    # Example: Calculate mean values of color channels
    mean_red = np.mean(image[:,:,0])
    mean_green = np.mean(image[:,:,1])
    mean_blue = np.mean(image[:,:,2])

    return hog_features.flatten(), mean_red, mean_green, mean_blue

def load_jpg_image(file_path):
    image = cv2.imread(file_path)
    if image is not None:
        image = cv2.resize(image, (256, 256))
        return image
    else:
        print(f"Unable to read image: {file_path}")
        return np.array([])

# Specify your image directory
path = "/content/drive/MyDrive/MTP_Rice_Dataset/Stressed"

# Get a sorted list of image names
image_names = sorted(os.listdir(path))

# Initialize lists to store features
hog_features_list = []
mean_red_list = []
mean_green_list = []
mean_blue_list = []

# Iterate through images in the directory
for file_name in image_names:
    file_path = os.path.join(path, file_name)
    image = load_jpg_image(file_path)

    if len(image) == 0:
        continue

    # Extract features from the image
    hog_features, mean_red, mean_green, mean_blue = extract_features(image)

    # Append features to lists
    hog_features_list.append(hog_features)
    mean_red_list.append(mean_red)
    mean_green_list.append(mean_green)
    mean_blue_list.append(mean_blue)

# Create a DataFrame to store the features
data = {
    'Image Name': image_names,
    'HOG Feature 1': hog_features_list,
    'HOG Feature 2': hog_features_list,  # Add more HOG features if needed
    'Mean Red Value': mean_red_list,
    'Mean Green Value': mean_green_list,
    'Mean Blue Value': mean_blue_list
}

image_list = pd.DataFrame(data)

# Display the DataFrame
print(image_list)

# Function to visualize HOG features using histograms
def visualize_hog_histogram(hog_features_list):
    plt.figure(figsize=(10, 6))
    for features in hog_features_list:
        plt.hist(features.flatten(), bins=50, alpha=0.5)

    plt.title('Histogram of HOG Features')
    plt.xlabel('Feature Value')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

# Visualize HOG features using histograms
visualize_hog_histogram(image_list['HOG Feature 1'])

from scipy import stats

# Function to visualize HOG features using histograms with different transformations
def visualize_hog_histogram(hog_features_list, transformation='log'):
    plt.figure(figsize=(10, 6))
    for features in hog_features_list:
        if transformation == 'log':
            transformed_features = np.log1p(features.flatten())
            title = 'Histogram of Transformed HOG Features (Logarithmic)'
        elif transformation == 'sqrt':
            transformed_features = np.sqrt(features.flatten())
            title = 'Histogram of Transformed HOG Features (Square Root)'
        elif transformation == 'cbrt':
            transformed_features = np.cbrt(features.flatten())
            title = 'Histogram of Transformed HOG Features (Cube Root)'
        elif transformation == 'boxcox':
            transformed_features, _ = stats.boxcox(features.flatten() + 1)
            title = 'Histogram of Transformed HOG Features (Box-Cox)'
        else:
            raise ValueError("Invalid transformation type. Choose from 'log', 'sqrt', 'cbrt', or 'boxcox'.")

        plt.hist(transformed_features, bins=50, alpha=0.5)

    plt.title(title)
    plt.xlabel('Transformed Feature Value')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

# Visualize transformed HOG features using histograms with different transformations
visualize_hog_histogram(image_list['HOG Feature 1'], transformation='sqrt')

def extract_features(image):
    # Example: Extract HOG features
    hog = cv2.HOGDescriptor()
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    hog_features = hog.compute(gray)

    # Example: Calculate mean values of color channels
    mean_red = np.mean(image[:,:,0])
    mean_green = np.mean(image[:,:,1])
    mean_blue = np.mean(image[:,:,2])

    return hog_features.flatten(), mean_red, mean_green, mean_blue

def load_jpg_image(file_path):
    image = cv2.imread(file_path)
    if image is not None:
        image = cv2.resize(image, (256, 256))
        return image
    else:
        print(f"Unable to read image: {file_path}")
        return np.array([])

# Specify your image directory
path = "/content/drive/MyDrive/MTP_Rice_Dataset/Controlled"

# Get a sorted list of image names
image_names = sorted(os.listdir(path))

# Initialize lists to store features
hog_features_list = []
mean_red_list = []
mean_green_list = []
mean_blue_list = []

# Iterate through images in the directory
for file_name in image_names:
    file_path = os.path.join(path, file_name)
    image = load_jpg_image(file_path)

    if len(image) == 0:
        continue

    # Extract features from the image
    hog_features, mean_red, mean_green, mean_blue = extract_features(image)

    # Append features to lists
    hog_features_list.append(hog_features)
    mean_red_list.append(mean_red)
    mean_green_list.append(mean_green)
    mean_blue_list.append(mean_blue)

# Create a DataFrame to store the features
data = {
    'Image Name': image_names,
    'HOG Feature 1': hog_features_list,
    'HOG Feature 2': hog_features_list,  # Add more HOG features if needed
    'Mean Red Value': mean_red_list,
    'Mean Green Value': mean_green_list,
    'Mean Blue Value': mean_blue_list
}

label_list = pd.DataFrame(data)

# Display the DataFrame
print(label_list)

# Function to visualize HOG features using histograms
def visualize_hog_histogram(hog_features_list):
    plt.figure(figsize=(10, 6))
    for features in hog_features_list:
        plt.hist(features.flatten(), bins=50, alpha=0.5)

    plt.title('Histogram of HOG Features')
    plt.xlabel('Feature Value')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

# Visualize HOG features using histograms
visualize_hog_histogram(label_list['HOG Feature 1'])

from scipy import stats

# Function to visualize HOG features using histograms with different transformations
def visualize_hog_histogram(hog_features_list, transformation='log'):
    plt.figure(figsize=(10, 6))
    for features in hog_features_list:
        if transformation == 'log':
            transformed_features = np.log1p(features.flatten())  # Apply logarithmic transformation
            title = 'Histogram of Transformed HOG Features (Logarithmic)'
        elif transformation == 'sqrt':
            transformed_features = np.sqrt(features.flatten())  # Apply square root transformation
            title = 'Histogram of Transformed HOG Features (Square Root)'
        elif transformation == 'cbrt':
            transformed_features = np.cbrt(features.flatten())  # Apply cube root transformation
            title = 'Histogram of Transformed HOG Features (Cube Root)'
        elif transformation == 'boxcox':
            transformed_features, _ = stats.boxcox(features.flatten() + 1)  # Apply Box-Cox transformation
            title = 'Histogram of Transformed HOG Features (Box-Cox)'
        else:
            raise ValueError("Invalid transformation type. Choose from 'log', 'sqrt', 'cbrt', or 'boxcox'.")

        plt.hist(transformed_features, bins=50, alpha=0.5)

    plt.title(title)
    plt.xlabel('Transformed Feature Value')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

# Visualize transformed HOG features using histograms with different transformations
visualize_hog_histogram(label_list['HOG Feature 1'], transformation='sqrt')

image_list, label_list = [], []
all_labels = ['Stressed', 'Controlled']
binary_labels = [0, 1]
temp = -1

X = np.array(image_list)
y = np.array(label_list)

df = pd.DataFrame(label_list, columns=['Labels'])
label_counts = df.value_counts()
print(label_counts.head())

df[0].shape

x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size = 0.2, random_state = 10)

x_train = np.array(x_train, dtype=np.float16) / 255.0
x_test = np.array(x_test, dtype=np.float16) / 255.0
x_train = x_train.reshape(-1, 256, 256, 3)
x_test = x_test.reshape(-1, 256, 256, 3)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

model = Sequential()
model.add(Conv2D(32, (3,3), padding="same", input_shape=(256,256,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(3,3)))
model.add(Dropout(0.2))
model.add(Conv2D(64, (3,3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(8, activation="relu"))
model.add(Dense(2, activation="softmax"))
model.summary()

model.compile(loss = 'binary_crossentropy', optimizer = Adam(0.0001), metrics=['accuracy'])

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=10)

early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)

epochs = 30
batch_size = 16
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stop])

model.save("/content/drive/MyDrive/Model_1/Stress_Prediction.hs")

plt.figure(figsize=(12, 5))
plt.plot(history.history['accuracy'], color='r')
plt.plot(history.history['val_accuracy'], color='b')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['Train', 'Validation'])
plt.grid(True)
plt.show()

print("Calculating model accuracy")
scores = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {scores[1]*100}")

# Making predictions and evaluating the model
y_pred = model.predict(x_test)
y_pred = (y_pred >= 0.5)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print(classification_report(y_test, y_pred))

# Define the classes and their corresponding metrics
classes = ['Class 0', 'Class 1']
precision = [0.83, 0.91]
recall = [0.93, 0.80]
f1_score = [0.88, 0.85]

# Plotting the metrics for each class
x = np.arange(len(classes))
width = 0.3

fig, ax = plt.subplots(figsize=(8, 6))
bars1 = ax.bar(x - width, precision, width, label='Precision')
bars2 = ax.bar(x, recall, width, label='Recall')
bars3 = ax.bar(x + width, f1_score, width, label='F1-score')

# Add labels, title, and legend
ax.set_xlabel('Classes')
ax.set_ylabel('Scores')
ax.set_title('Precision, Recall, and F1-score by Class')
ax.set_xticks(x)
ax.set_xticklabels(classes)
ax.legend()

# Show plot
plt.grid(True)
plt.show()

"""##**Random Forest**"""

import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import cv2

# Function to load and preprocess a JPG image
def load_and_preprocess_image(image_path, target_size=(256, 256)):
    try:
        # Load the image using OpenCV
        image = cv2.imread(image_path)
        # Resize the image to the target size
        image = cv2.resize(image, target_size)
        # Flatten the image array
        image_array = image.flatten()
        return image_array
    except Exception as e:
        print(f"Error loading image {image_path}: {e}")
        return None

dir = "/content/drive/MyDrive/MTP_Rice_Dataset"
image_list, label_list = [], []
all_labels = ['Stressed', 'Controlled']
binary_labels = [0, 1]
temp = -1

for directory in all_labels:
    plant_image_list = os.listdir(f"{dir}/{directory}")
    temp += 1
    for file_name in plant_image_list:
        image_path = f"{dir}/{directory}/{file_name}"
        image_array = load_and_preprocess_image(image_path)
        if image_array is not None:
            image_list.append(image_array)
            label_list.append(binary_labels[temp])

X = np.array(image_list)
y = np.array(label_list)

from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
import numpy as np

# Define a range of values for n_estimators (number of trees)
n_estimators_values = [10]

# Initialize lists to store mean training and testing accuracy values
mean_train_accuracy = []
mean_test_accuracy = []

# Iterate over each value of n_estimators
for n_estimators in n_estimators_values:
    # Initialize the Random Forest classifier
    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=5, min_samples_split=10, max_features=0.5, random_state=42)

    # Perform cross-validation to get accuracy scores
    train_accuracy_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5, scoring='accuracy')
    test_accuracy_scores = cross_val_score(rf_classifier, X_test, y_test, cv=5, scoring='accuracy')

    # Calculate mean accuracy scores
    mean_train_accuracy.append(np.mean(train_accuracy_scores))
    mean_test_accuracy.append(np.mean(test_accuracy_scores))

# Plotting the mean training and testing accuracy
plt.plot(n_estimators_values, mean_train_accuracy, marker='o', linestyle='-', label='Training Accuracy')
plt.plot(n_estimators_values, mean_test_accuracy, marker='o', linestyle='-', label='Testing Accuracy')
plt.xlabel('Number of Trees (n_estimators)')
plt.ylabel('Accuracy')
plt.title('Mean Training and Testing Accuracy vs. Number of Trees')
plt.legend()
plt.grid(True)
plt.show()

bar_width = 0.2

# Plotting the mean training and testing accuracy
fig, ax = plt.subplots()
index = np.arange(len(n_estimators_values))
bar_train = ax.bar(index, mean_train_accuracy, bar_width, label='Training Accuracy')
bar_test = ax.bar(index + bar_width, mean_test_accuracy, bar_width, label='Testing Accuracy')

# Add labels, title, and legend
ax.set_xlabel('Number of Trees (n_estimators)')
ax.set_ylabel('Accuracy')
ax.set_title('Mean Training and Testing Accuracy vs. Number of Trees')
ax.set_xticks(index + bar_width / 2)
ax.set_xticklabels(n_estimators_values)
ax.legend()

plt.grid(True)
plt.show()

# Calculate mean accuracy scores
mean_train_accuracy = np.mean(train_accuracy_scores)
mean_test_accuracy = np.mean(test_accuracy_scores)

print("Mean Training Accuracy:", mean_train_accuracy)
print("Mean Testing Accuracy:", mean_test_accuracy)

# Generate the classification report
report = classification_report(y_test, y_pred)

print("Classification Report:")
print(report)

import matplotlib.pyplot as plt
import numpy as np

# Define the classes and their corresponding metrics
classes = ['Class 0', 'Class 1']
precision = [0.89, 0.96]
recall = [0.94, 0.9]
f1_score = [0.92, 0.96]

# Plotting the metrics for each class
x = np.arange(len(classes))
width = 0.3

fig, ax = plt.subplots(figsize=(8, 6))
bars1 = ax.bar(x - width, precision, width, label='Precision')
bars2 = ax.bar(x, recall, width, label='Recall')
bars3 = ax.bar(x + width, f1_score, width, label='F1-score')

# Add labels, title, and legend
ax.set_xlabel('Classes')
ax.set_ylabel('Scores')
ax.set_title('Precision, Recall, and F1-score by Class')
ax.set_xticks(x)
ax.set_xticklabels(classes)
ax.legend()

# Show plot
plt.grid(True)
plt.show()

# Define precision, recall, and support for each class
precision_class_0 = 0.89
recall_class_0 = 0.94
support_class_0 = 80

precision_class_1 = 0.96
recall_class_1 = 0.9
support_class_1 = 76

# Calculate the overall accuracy
total_samples = support_class_0 + support_class_1
accuracy = ((precision_class_0 * support_class_0) + (recall_class_1 * support_class_1)) / total_samples

print("Overall Accuracy:", accuracy)